{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Teste Engenheiro de Dados - Mesha Tecnologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação das Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: findspark in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: install-jdk in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (1.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark\n",
    "!pip install pandas \n",
    "!pip install install-jdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Dependencias e Inicialização do PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('PySpark MySQL Connection') \\\n",
    "        .master('local[*]') \\\n",
    "        .config(\"spark.jars\", \"/workspace/teste-engenheiro-de-dados/jars/mysql-connector-j-8.0.33.jar\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3545515851.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[149], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pyspark --jars \"/workspace/teste-engenheiro-de-dados/jars/mysql-connector-java-8.0.13.jar\"\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pyspark --jars \"/workspace/teste-engenheiro-de-dados/jars/mysql-connector-java-8.0.13.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.5.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f5ae7a5d0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/teste-engenheiro-de-dados/dados/row/DADOS/MICRODADOS_ENEM_2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem = spark.read.csv(path, sep=\";\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+-------+---------------+-----------+----------------+---------------+---------------+---------+---------+------------+----------------+-------------------+---------+---------+----------------------+------------------+---------------+------------------+-------------------+-----------+-----------+--------------+--------------+--------------+--------------+-----------+-----------+-----------+-----------+----------+----------+----------+----------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----------------+-------------+-------------+-------------+-------------+-------------+---------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|NU_INSCRICAO|NU_ANO|TP_FAIXA_ETARIA|TP_SEXO|TP_ESTADO_CIVIL|TP_COR_RACA|TP_NACIONALIDADE|TP_ST_CONCLUSAO|TP_ANO_CONCLUIU|TP_ESCOLA|TP_ENSINO|IN_TREINEIRO|CO_MUNICIPIO_ESC|   NO_MUNICIPIO_ESC|CO_UF_ESC|SG_UF_ESC|TP_DEPENDENCIA_ADM_ESC|TP_LOCALIZACAO_ESC|TP_SIT_FUNC_ESC|CO_MUNICIPIO_PROVA| NO_MUNICIPIO_PROVA|CO_UF_PROVA|SG_UF_PROVA|TP_PRESENCA_CN|TP_PRESENCA_CH|TP_PRESENCA_LC|TP_PRESENCA_MT|CO_PROVA_CN|CO_PROVA_CH|CO_PROVA_LC|CO_PROVA_MT|NU_NOTA_CN|NU_NOTA_CH|NU_NOTA_LC|NU_NOTA_MT|     TX_RESPOSTAS_CN|     TX_RESPOSTAS_CH|     TX_RESPOSTAS_LC|     TX_RESPOSTAS_MT|TP_LINGUA|      TX_GABARITO_CN|      TX_GABARITO_CH|      TX_GABARITO_LC|      TX_GABARITO_MT|TP_STATUS_REDACAO|NU_NOTA_COMP1|NU_NOTA_COMP2|NU_NOTA_COMP3|NU_NOTA_COMP4|NU_NOTA_COMP5|NU_NOTA_REDACAO|Q001|Q002|Q003|Q004|Q005|Q006|Q007|Q008|Q009|Q010|Q011|Q012|Q013|Q014|Q015|Q016|Q017|Q018|Q019|Q020|Q021|Q022|Q023|Q024|Q025|\n",
      "+------------+------+---------------+-------+---------------+-----------+----------------+---------------+---------------+---------+---------+------------+----------------+-------------------+---------+---------+----------------------+------------------+---------------+------------------+-------------------+-----------+-----------+--------------+--------------+--------------+--------------+-----------+-----------+-----------+-----------+----------+----------+----------+----------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----------------+-------------+-------------+-------------+-------------+-------------+---------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|200006271946|  2020|             11|      F|              1|          2|               1|              1|             11|        1|     null|           0|            null|               null|     null|     null|                  null|              null|           null|           1501402|              Bel�m|         15|         PA|             0|             0|             0|             0|       null|       null|       null|       null|      null|      null|      null|      null|                null|                null|                null|                null|        1|                null|                null|                null|                null|             null|         null|         null|         null|         null|         null|           null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|200001195856|  2020|             11|      M|              2|          3|               1|              1|             11|        1|     null|           0|            null|               null|     null|     null|                  null|              null|           null|           2408102|              Natal|         24|         RN|             1|             1|             1|             1|        702|        689|        693|        698|     604.1|     661.7|     595.3|     711.3|BCBDBDCCCDBDDBADE...|BCAECABCDCEBDBBBD...|99999CADDEDADBAAB...|EBEBDEDAECBADCADD...|        1|ABBACBCCCDDDDBAEE...|BCEECDBCCDEBDBBBB...|99999CBDDEDBDBACE...|BBEADECAECBBXCEBA...|                1|          120|          120|          120|          120|          100|            580|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|200001943954|  2020|              4|      F|              2|          3|               2|              2|              0|        2|        1|           0|         2927408|           Salvador|       29|       BA|                     2|                 1|              1|           2927408|           Salvador|         29|         BA|             0|             0|             0|             0|       null|       null|       null|       null|      null|      null|      null|      null|                null|                null|                null|                null|        0|                null|                null|                null|                null|             null|         null|         null|         null|         null|         null|           null|   B|   C|   A|   D|   3|   B|   A|   B|   A|   A|   A|   B|   A|   B|   A|   B|   A|   A|   B|   A|   A|   A|   A|   A|   A|\n",
      "|200001908998|  2020|              2|      M|              1|          3|               1|              2|              0|        2|        1|           0|         3547304|Santana de Parna�ba|       35|       SP|                     3|                 1|              1|           3547304|Santana de Parna�ba|         35|         SP|             1|             1|             1|             1|        700|        688|        692|        696|     620.8|       675|     624.2|     759.4|EBEDCCCDCBDBAECAE...|DABCCACCBCCDCADBD...|DCEAB99999AADAECC...|CBDBDCCDDEECBAABB...|        0|BDECCACBEBDEAEDAE...|DABCCAECBABECADBD...|DCEAD99999AADACCC...|EBDBXCCDAEECBAABA...|                1|          140|          200|          140|          120|          160|            760|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|200001634757|  2020|              4|      F|              1|          3|               2|              1|              1|        1|     null|           0|            null|               null|     null|     null|                  null|              null|           null|           3121605|         Diamantina|         31|         MG|             0|             0|             0|             0|       null|       null|       null|       null|      null|      null|      null|      null|                null|                null|                null|                null|        1|                null|                null|                null|                null|             null|         null|         null|         null|         null|         null|           null|   B|   G|   B|   B|   3|   B|   A|   B|   D|   A|   A|   B|   A|   B|   A|   A|   A|   A|   B|   A|   B|   B|   A|   A|   B|\n",
      "+------------+------+---------------+-------+---------------+-----------+----------------+---------------+---------------+---------+---------+------------+----------------+-------------------+---------+---------+----------------------+------------------+---------------+------------------+-------------------+-----------+-----------+--------------+--------------+--------------+--------------+-----------+-----------+-----------+-----------+----------+----------+----------+----------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----------------+-------------+-------------+-------------+-------------+-------------+---------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enem.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NU_INSCRICAO: string (nullable = true)\n",
      " |-- NU_ANO: string (nullable = true)\n",
      " |-- TP_FAIXA_ETARIA: string (nullable = true)\n",
      " |-- TP_SEXO: string (nullable = true)\n",
      " |-- TP_ESTADO_CIVIL: string (nullable = true)\n",
      " |-- TP_COR_RACA: string (nullable = true)\n",
      " |-- TP_NACIONALIDADE: string (nullable = true)\n",
      " |-- TP_ST_CONCLUSAO: string (nullable = true)\n",
      " |-- TP_ANO_CONCLUIU: string (nullable = true)\n",
      " |-- TP_ESCOLA: string (nullable = true)\n",
      " |-- TP_ENSINO: string (nullable = true)\n",
      " |-- IN_TREINEIRO: string (nullable = true)\n",
      " |-- CO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- CO_UF_ESC: string (nullable = true)\n",
      " |-- SG_UF_ESC: string (nullable = true)\n",
      " |-- TP_DEPENDENCIA_ADM_ESC: string (nullable = true)\n",
      " |-- TP_LOCALIZACAO_ESC: string (nullable = true)\n",
      " |-- TP_SIT_FUNC_ESC: string (nullable = true)\n",
      " |-- CO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- CO_UF_PROVA: string (nullable = true)\n",
      " |-- SG_UF_PROVA: string (nullable = true)\n",
      " |-- TP_PRESENCA_CN: string (nullable = true)\n",
      " |-- TP_PRESENCA_CH: string (nullable = true)\n",
      " |-- TP_PRESENCA_LC: string (nullable = true)\n",
      " |-- TP_PRESENCA_MT: string (nullable = true)\n",
      " |-- CO_PROVA_CN: string (nullable = true)\n",
      " |-- CO_PROVA_CH: string (nullable = true)\n",
      " |-- CO_PROVA_LC: string (nullable = true)\n",
      " |-- CO_PROVA_MT: string (nullable = true)\n",
      " |-- NU_NOTA_CN: string (nullable = true)\n",
      " |-- NU_NOTA_CH: string (nullable = true)\n",
      " |-- NU_NOTA_LC: string (nullable = true)\n",
      " |-- NU_NOTA_MT: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_CN: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_CH: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_LC: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_MT: string (nullable = true)\n",
      " |-- TP_LINGUA: string (nullable = true)\n",
      " |-- TX_GABARITO_CN: string (nullable = true)\n",
      " |-- TX_GABARITO_CH: string (nullable = true)\n",
      " |-- TX_GABARITO_LC: string (nullable = true)\n",
      " |-- TX_GABARITO_MT: string (nullable = true)\n",
      " |-- TP_STATUS_REDACAO: string (nullable = true)\n",
      " |-- NU_NOTA_COMP1: string (nullable = true)\n",
      " |-- NU_NOTA_COMP2: string (nullable = true)\n",
      " |-- NU_NOTA_COMP3: string (nullable = true)\n",
      " |-- NU_NOTA_COMP4: string (nullable = true)\n",
      " |-- NU_NOTA_COMP5: string (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: string (nullable = true)\n",
      " |-- Q001: string (nullable = true)\n",
      " |-- Q002: string (nullable = true)\n",
      " |-- Q003: string (nullable = true)\n",
      " |-- Q004: string (nullable = true)\n",
      " |-- Q005: string (nullable = true)\n",
      " |-- Q006: string (nullable = true)\n",
      " |-- Q007: string (nullable = true)\n",
      " |-- Q008: string (nullable = true)\n",
      " |-- Q009: string (nullable = true)\n",
      " |-- Q010: string (nullable = true)\n",
      " |-- Q011: string (nullable = true)\n",
      " |-- Q012: string (nullable = true)\n",
      " |-- Q013: string (nullable = true)\n",
      " |-- Q014: string (nullable = true)\n",
      " |-- Q015: string (nullable = true)\n",
      " |-- Q016: string (nullable = true)\n",
      " |-- Q017: string (nullable = true)\n",
      " |-- Q018: string (nullable = true)\n",
      " |-- Q019: string (nullable = true)\n",
      " |-- Q020: string (nullable = true)\n",
      " |-- Q021: string (nullable = true)\n",
      " |-- Q022: string (nullable = true)\n",
      " |-- Q023: string (nullable = true)\n",
      " |-- Q024: string (nullable = true)\n",
      " |-- Q025: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enem.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem.where('NU_ANO!=\"2020\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3028969"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enem.where(enem['NU_NOTA_REDACAO'].isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento na Processing Zone - Seleção de Columns, Correções dos tipos de dados e Transformação para o formato Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemSelecao = enem.select(\"NU_INSCRICAO\", \"TP_SEXO\", \"TP_COR_RACA\", \"CO_MUNICIPIO_ESC\", \"NO_MUNICIPIO_ESC\", \"SG_UF_ESC\", \"TP_PRESENCA_CN\", \"TP_PRESENCA_CH\", \"TP_PRESENCA_LC\", \"TP_PRESENCA_MT\", \"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_REDACAO\", \"TP_ST_CONCLUSAO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+----------------+-------------------+---------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------------+---------------+\n",
      "|NU_INSCRICAO|TP_SEXO|TP_COR_RACA|CO_MUNICIPIO_ESC|   NO_MUNICIPIO_ESC|SG_UF_ESC|TP_PRESENCA_CN|TP_PRESENCA_CH|TP_PRESENCA_LC|TP_PRESENCA_MT|NU_NOTA_CN|NU_NOTA_CH|NU_NOTA_LC|NU_NOTA_MT|NU_NOTA_REDACAO|TP_ST_CONCLUSAO|\n",
      "+------------+-------+-----------+----------------+-------------------+---------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------------+---------------+\n",
      "|200006271946|      F|          2|            null|               null|     null|             0|             0|             0|             0|      null|      null|      null|      null|           null|              1|\n",
      "|200001195856|      M|          3|            null|               null|     null|             1|             1|             1|             1|     604.1|     661.7|     595.3|     711.3|            580|              1|\n",
      "|200001943954|      F|          3|         2927408|           Salvador|       BA|             0|             0|             0|             0|      null|      null|      null|      null|           null|              2|\n",
      "|200001908998|      M|          3|         3547304|Santana de Parna�ba|       SP|             1|             1|             1|             1|     620.8|       675|     624.2|     759.4|            760|              2|\n",
      "|200001634757|      F|          3|            null|               null|     null|             0|             0|             0|             0|      null|      null|      null|      null|           null|              1|\n",
      "+------------+-------+-----------+----------------+-------------------+---------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enemSelecao.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção dos tipos dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, StringType, IntegerType \n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NU_INSCRICAO: string (nullable = true)\n",
      " |-- TP_SEXO: string (nullable = true)\n",
      " |-- TP_COR_RACA: string (nullable = true)\n",
      " |-- CO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- SG_UF_ESC: string (nullable = true)\n",
      " |-- TP_PRESENCA_CN: string (nullable = true)\n",
      " |-- TP_PRESENCA_CH: string (nullable = true)\n",
      " |-- TP_PRESENCA_LC: string (nullable = true)\n",
      " |-- TP_PRESENCA_MT: string (nullable = true)\n",
      " |-- NU_NOTA_CN: string (nullable = true)\n",
      " |-- NU_NOTA_CH: string (nullable = true)\n",
      " |-- NU_NOTA_LC: string (nullable = true)\n",
      " |-- NU_NOTA_MT: string (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: string (nullable = true)\n",
      " |-- TP_ST_CONCLUSAO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enemSelecao.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemSelecao.where(enemSelecao['TP_ST_CONCLUSAO'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemSelecaoTipos = enemSelecao\\\n",
    "    .withColumn(\n",
    "    \"TP_COR_RACA\",\n",
    "    enemSelecao[\"TP_COR_RACA\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"CO_MUNICIPIO_ESC\",\n",
    "    enemSelecao[\"CO_MUNICIPIO_ESC\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"TP_PRESENCA_CN\",\n",
    "    enemSelecao[\"TP_PRESENCA_CN\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"TP_PRESENCA_CH\",\n",
    "    enemSelecao[\"TP_PRESENCA_CH\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"TP_PRESENCA_LC\",\n",
    "    enemSelecao[\"TP_PRESENCA_LC\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"TP_PRESENCA_MT\",\n",
    "    enemSelecao[\"TP_PRESENCA_MT\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"NU_NOTA_CN\",\n",
    "    enemSelecao[\"NU_NOTA_CN\"].cast(DoubleType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"NU_NOTA_CH\",\n",
    "    enemSelecao[\"NU_NOTA_CH\"].cast(DoubleType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"NU_NOTA_LC\",\n",
    "    enemSelecao[\"NU_NOTA_LC\"].cast(DoubleType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"NU_NOTA_MT\",\n",
    "    enemSelecao[\"NU_NOTA_MT\"].cast(DoubleType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"NU_NOTA_REDACAO\",\n",
    "    enemSelecao[\"NU_NOTA_REDACAO\"].cast(IntegerType())\n",
    "    )\\\n",
    "    .withColumn(\n",
    "    \"TP_ST_CONCLUSAO\",\n",
    "    enemSelecao[\"TP_ST_CONCLUSAO\"].cast(IntegerType())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemSelecaoTipos.where(enemSelecaoTipos['TP_ST_CONCLUSAO'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NU_INSCRICAO: string (nullable = true)\n",
      " |-- TP_SEXO: string (nullable = true)\n",
      " |-- TP_COR_RACA: integer (nullable = true)\n",
      " |-- CO_MUNICIPIO_ESC: integer (nullable = true)\n",
      " |-- NO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- SG_UF_ESC: string (nullable = true)\n",
      " |-- TP_PRESENCA_CN: integer (nullable = true)\n",
      " |-- TP_PRESENCA_CH: integer (nullable = true)\n",
      " |-- TP_PRESENCA_LC: integer (nullable = true)\n",
      " |-- TP_PRESENCA_MT: integer (nullable = true)\n",
      " |-- NU_NOTA_CN: double (nullable = true)\n",
      " |-- NU_NOTA_CH: double (nullable = true)\n",
      " |-- NU_NOTA_LC: double (nullable = true)\n",
      " |-- NU_NOTA_MT: double (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: integer (nullable = true)\n",
      " |-- TP_ST_CONCLUSAO: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enemSelecaoTipos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "novosNomes = {'NU_INSCRICAO':'NumInscricao', 'TP_SEXO':'Sexo', 'TP_COR_RACA':'Etnia', 'CO_MUNICIPIO_ESC':'CodMunicipioEsc', 'NO_MUNICIPIO_ESC':'NomMunicipioEsc', 'SG_UF_ESC':'EstadoEsc', 'TP_PRESENCA_CN':'PresencaCN', 'TP_PRESENCA_CH':'PresencaCH', 'TP_PRESENCA_LC':'PresencaLC', 'TP_PRESENCA_MT':'PresencaMT', 'NU_NOTA_CN':'NotaCN', 'NU_NOTA_CH':'NotaCH', 'NU_NOTA_LC':'NotaLC', 'NU_NOTA_MT':'NotaMT', 'NU_NOTA_REDACAO':'NotaRedacao', 'TP_ST_CONCLUSAO':'SituacaoConclusao'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in novosNomes.items():\n",
    "    enemSelecaoTipos = enemSelecaoTipos.withColumnRenamed(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NumInscricao: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- Etnia: integer (nullable = true)\n",
      " |-- CodMunicipioEsc: integer (nullable = true)\n",
      " |-- NomMunicipioEsc: string (nullable = true)\n",
      " |-- EstadoEsc: string (nullable = true)\n",
      " |-- PresencaCN: integer (nullable = true)\n",
      " |-- PresencaCH: integer (nullable = true)\n",
      " |-- PresencaLC: integer (nullable = true)\n",
      " |-- PresencaMT: integer (nullable = true)\n",
      " |-- NotaCN: double (nullable = true)\n",
      " |-- NotaCH: double (nullable = true)\n",
      " |-- NotaLC: double (nullable = true)\n",
      " |-- NotaMT: double (nullable = true)\n",
      " |-- NotaRedacao: integer (nullable = true)\n",
      " |-- SituacaoConclusao: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enemSelecaoTipos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação para o formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathParquet = \"/workspace/teste-engenheiro-de-dados/dados/processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "23/06/28 16:51:55 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "23/06/28 16:52:02 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "23/06/28 16:52:02 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "23/06/28 16:52:02 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "23/06/28 16:52:02 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/06/28 16:52:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/06/28 16:52:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/06/28 16:52:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/06/28 16:52:03 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "enemSelecaoTipos.write.parquet(\n",
    "    pathParquet,\n",
    "    mode = \"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemParquet = spark.read.parquet(\n",
    "    pathParquet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+-----+---------------+---------------+---------+----------+----------+----------+----------+------+------+------+------+-----------+-----------------+\n",
      "|NumInscricao|Sexo|Etnia|CodMunicipioEsc|NomMunicipioEsc|EstadoEsc|PresencaCN|PresencaCH|PresencaLC|PresencaMT|NotaCN|NotaCH|NotaLC|NotaMT|NotaRedacao|SituacaoConclusao|\n",
      "+------------+----+-----+---------------+---------------+---------+----------+----------+----------+----------+------+------+------+------+-----------+-----------------+\n",
      "|200003297356|   F|    2|           null|           null|     null|         0|         0|         0|         0|  null|  null|  null|  null|       null|                1|\n",
      "|200003373109|   F|    2|           null|           null|     null|         0|         0|         0|         0|  null|  null|  null|  null|       null|                1|\n",
      "|200004404163|   F|    1|           null|           null|     null|         0|         0|         0|         0|  null|  null|  null|  null|       null|                3|\n",
      "|200001704986|   M|    1|           null|           null|     null|         1|         1|         1|         1| 578.7| 624.6| 612.1| 638.7|        880|                1|\n",
      "|200001049116|   F|    1|           null|           null|     null|         1|         1|         1|         1| 643.5| 645.9| 592.8| 682.6|        620|                1|\n",
      "+------------+----+-----+---------------+---------------+---------+----------+----------+----------+----------+------+------+------+------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enemParquet.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5783109"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemParquet.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curated Zone - Criando as tabelas para cada pergunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemParquet.createOrReplaceTempView(\"enemView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Qual a escola com a maior média de notas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "escolaMaiorMedia = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            CodMunicipioEsc, NomMunicipioEsc, \n",
    "            EstadoEsc, ROUND(AVG(MediaNotas), 2) AS MediaNotas\n",
    "        FROM\n",
    "            (SELECT\n",
    "                NumInscricao, CodMunicipioEsc, NomMunicipioEsc, EstadoEsc, \n",
    "                ROUND((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5, 2) AS MediaNotas\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE \n",
    "                    SituacaoConclusao == 2 \n",
    "                AND \n",
    "                    CodMunicipioEsc IS NOT NULL \n",
    "                AND \n",
    "                    NotaMT IS NOT NULL\n",
    "                AND\n",
    "                    NotaCH IS NOT NULL\n",
    "                AND\n",
    "                    NotaCN IS NOT NULL\n",
    "                AND\n",
    "                    NotaLC IS NOT NULL\n",
    "                AND \n",
    "                    NotaRedacao IS NOT NULL\n",
    "            )\n",
    "        GROUP BY CodMunicipioEsc, NomMunicipioEsc, EstadoEsc  \n",
    "        ORDER BY MediaNotas DESC\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------+----------+\n",
      "|CodMunicipioEsc|     NomMunicipioEsc|EstadoEsc|MediaNotas|\n",
      "+---------------+--------------------+---------+----------+\n",
      "|        3158904| Santana do Manhua�u|       MG|    706.56|\n",
      "|        4313466|          Novo Xingu|       RS|     704.9|\n",
      "|        4305850|    Coqueiros do Sul|       RS|    693.52|\n",
      "|        4117297|      Novo Itacolomi|       PR|     692.7|\n",
      "|        3107000|           Biquinhas|       MG|    685.64|\n",
      "|        3147808|         Passa Vinte|       MG|    681.74|\n",
      "|        3160009|Santo Ant�nio do ...|       MG|     670.8|\n",
      "|        3170651|Vargem Grande do ...|       MG|    668.77|\n",
      "|        3149408|      Pedro Teixeira|       MG|    656.16|\n",
      "|        4304853|        Carlos Gomes|       RS|    654.44|\n",
      "+---------------+--------------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "escolaMaiorMedia.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5425"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escolaMaiorMedia.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o827.save.\n: java.lang.ClassNotFoundException: com.mysql.cj.jdbc.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat jdk.internal.reflect.GeneratedMethodAccessor152.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mescolaMaiorMedia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.mysql.cj.jdbc.Driver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc:mysql://172.18.0.2:3306/mesha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmesha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmesha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmesha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 8\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1396\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o827.save.\n: java.lang.ClassNotFoundException: com.mysql.cj.jdbc.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat jdk.internal.reflect.GeneratedMethodAccessor152.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "escolaMaiorMedia.write\\\n",
    "  .format(\"jdbc\")\\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\\\n",
    "  .option(\"url\", \"jdbc:mysql://172.18.0.2:3306/mesha\")\\\n",
    "  .option(\"dbtable\", \"mesha\")\\\n",
    "  .option(\"user\", \"mesha\")\\\n",
    "  .option(\"password\", \"mesha\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Qual o aluno com a maior média de notas e o valor dessa média?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alunoMaiorNota = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            (SELECT\n",
    "                NumInscricao, Sexo, \n",
    "                Etnia, NomMunicipioEsc, \n",
    "                EstadoEsc, \n",
    "                SituacaoConclusao,\n",
    "                ROUND((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5, 2) AS MediaNotas\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE \n",
    "                    NotaMT IS NOT NULL\n",
    "                AND\n",
    "                    NotaCH IS NOT NULL\n",
    "                AND\n",
    "                    NotaCN IS NOT NULL\n",
    "                AND\n",
    "                    NotaLC IS NOT NULL\n",
    "                AND \n",
    "                    NotaRedacao IS NOT NULL)\n",
    "        ORDER BY MediaNotas DESC\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:============================>                            (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+-----+---------------+---------+-----------------+----------+\n",
      "|NumInscricao|Sexo|Etnia|NomMunicipioEsc|EstadoEsc|SituacaoConclusao|MediaNotas|\n",
      "+------------+----+-----+---------------+---------+-----------------+----------+\n",
      "|200005996961|   M|    1|           null|     null|                1|    858.58|\n",
      "|200004812135|   M|    1|           null|     null|                1|    852.86|\n",
      "|200001357436|   M|    1| Rio de Janeiro|       RJ|                2|    852.76|\n",
      "|200004002694|   M|    1|           null|     null|                1|     851.5|\n",
      "|200001850224|   F|    1|      S�o Paulo|       SP|                2|    851.34|\n",
      "|200006051511|   F|    1|    Jo�o Pessoa|       PB|                2|    850.74|\n",
      "|200003688741|   M|    1|           null|     null|                1|    849.34|\n",
      "|200006619550|   F|    1|           null|     null|                1|    847.82|\n",
      "|200001993301|   M|    1|           null|     null|                1|    847.68|\n",
      "|200004146848|   F|    1|           null|     null|                1|     847.6|\n",
      "+------------+----+-----+---------------+---------+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "alunoMaiorNota.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe and View Etnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|codEtnia|    nomeEtnia|\n",
      "+--------+-------------+\n",
      "|       0|Nao declarado|\n",
      "|       1|       Branca|\n",
      "|       2|        Preta|\n",
      "|       3|        Parda|\n",
      "|       4|      Amarela|\n",
      "|       5|     Indigena|\n",
      "+--------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 83:>                                                       (0 + 11) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "etniaColumns = [\"codEtnia\", \"nomeEtnia\"]\n",
    "etniaNome = [(0, \"Nao declarado\"), (1, \"Branca\"), (2, \"Preta\"), (3, \"Parda\"), (4, \"Amarela\"), (5, \"Indigena\")]\n",
    "etniaDataframe = spark.createDataFrame(etniaNome, etniaColumns)\n",
    "etniaDataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "etniaDataframe.createOrReplaceTempView(\"etniaView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe and View SituacaoConclusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|codCon|             nomeCon|\n",
      "+------+--------------------+\n",
      "|     1|           Concluido|\n",
      "|     2|Cursando/Conclusa...|\n",
      "|     3|Cursando/Conclusa...|\n",
      "|     4|Sem Conclusao/Pre...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 86:>                                                       (0 + 11) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sitConColumns = [\"codCon\", \"nomeCon\"]\n",
    "sitConNome = [(1, \"Concluido\"), (2, \"Cursando/Conclusao 2020\"), (3, \"Cursando/Conclusao Apos 2020\"), (4, \"Sem Conclusao/Previsao\")]\n",
    "sitConDataframe = spark.createDataFrame(sitConNome, sitConColumns)\n",
    "sitConDataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitConDataframe.createOrReplaceTempView(\"sitConView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Tables Etnia e SituaçãoConclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "alunoMaiorNota = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            A.NumInscricao, A.Sexo,\n",
    "            B.nomeEtnia AS Etnia,\n",
    "            A.NomMunicipioEsc, A.EstadoEsc,\n",
    "            C.nomeCon AS SituacaoConclusao,\n",
    "            A.MediaNotas\n",
    "        FROM\n",
    "            (SELECT\n",
    "                NumInscricao, Sexo, \n",
    "                Etnia, NomMunicipioEsc, \n",
    "                EstadoEsc, \n",
    "                SituacaoConclusao,\n",
    "                ROUND((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5, 2) AS MediaNotas\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE \n",
    "                    NotaMT IS NOT NULL\n",
    "                AND\n",
    "                    NotaCH IS NOT NULL\n",
    "                AND\n",
    "                    NotaCN IS NOT NULL\n",
    "                AND\n",
    "                    NotaLC IS NOT NULL\n",
    "                AND \n",
    "                    NotaRedacao IS NOT NULL) A\n",
    "        INNER JOIN\n",
    "            etniaView B\n",
    "            ON codEtnia == Etnia\n",
    "        INNER JOIN\n",
    "            sitConView C\n",
    "            ON codCon == SituacaoConclusao\n",
    "        ORDER BY MediaNotas DESC\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+------+---------------+---------+--------------------+----------+\n",
      "|NumInscricao|Sexo| Etnia|NomMunicipioEsc|EstadoEsc|   SituacaoConclusao|MediaNotas|\n",
      "+------------+----+------+---------------+---------+--------------------+----------+\n",
      "|200005996961|   M|Branca|           null|     null|           Concluido|    858.58|\n",
      "|200004812135|   M|Branca|           null|     null|           Concluido|    852.86|\n",
      "|200001357436|   M|Branca| Rio de Janeiro|       RJ|Cursando/Conclusa...|    852.76|\n",
      "|200004002694|   M|Branca|           null|     null|           Concluido|     851.5|\n",
      "|200001850224|   F|Branca|      S�o Paulo|       SP|Cursando/Conclusa...|    851.34|\n",
      "|200006051511|   F|Branca|    Jo�o Pessoa|       PB|Cursando/Conclusa...|    850.74|\n",
      "|200003688741|   M|Branca|           null|     null|           Concluido|    849.34|\n",
      "|200006619550|   F|Branca|           null|     null|           Concluido|    847.82|\n",
      "|200001993301|   M|Branca|           null|     null|           Concluido|    847.68|\n",
      "|200004146848|   F|Branca|           null|     null|           Concluido|     847.6|\n",
      "+------------+----+------+---------------+---------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "alunoMaiorNota.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Qual a média geral?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaGeral = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            ROUND(AVG(ROUND((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5, 2)), 2) AS MediaGeral\n",
    "        FROM\n",
    "            (SELECT \n",
    "                *\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                    NotaMT IS NOT NULL\n",
    "                AND\n",
    "                    NotaCH IS NOT NULL\n",
    "                AND\n",
    "                    NotaCN IS NOT NULL\n",
    "                AND\n",
    "                    NotaLC IS NOT NULL\n",
    "                AND \n",
    "                    NotaRedacao IS NOT NULL\n",
    "            )\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 42:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|MediaGeral|\n",
      "+----------+\n",
      "|    526.58|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 42:======================================>                 (11 + 5) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mediaGeral.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Qual o % de Ausentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausentesEnem = spark.sql(\"\"\"\n",
    "            SELECT\n",
    "                COUNT(NumInscricao) AS NumAusentes\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE \n",
    "                    PresencaCN = 0\n",
    "                OR\n",
    "                    PresencaCH = 0\n",
    "                OR\n",
    "                    PresencaLC = 0\n",
    "                OR\n",
    "                    PresencaMT = 0\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|NumAusentes|\n",
      "+-----------+\n",
      "|    3192751|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ausentesEnem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEnem = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            COUNT(NumInscricao) AS NumTotal\n",
    "        FROM\n",
    "            enemView\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|NumTotal|\n",
      "+--------+\n",
      "| 5783109|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "totalEnem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausentesEnem.createOrReplaceTempView(\"ausentesEnemView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEnem.createOrReplaceTempView(\"totalEnemView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagemAusentesEnem = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            B.NumTotal, A.NumAusentes, \n",
    "            ROUND(((A.NumAusentes*100)/B.NumTotal), 2) AS PorcentagemAusentes\n",
    "        FROM\n",
    "            ausentesEnemView AS A,\n",
    "            totalEnemView AS B\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------------+\n",
      "|NumTotal|NumAusentes|PorcentagemAusentes|\n",
      "+--------+-----------+-------------------+\n",
      "| 5783109|    3192751|              55.21|\n",
      "+--------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "porcentagemAusentesEnem.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe and View Presenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|codPre|  nomePre|\n",
      "+------+---------+\n",
      "|     0|   Faltou|\n",
      "|     1| Presente|\n",
      "|     2|Eliminado|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "presencaColumns = [\"codPre\", \"nomePre\"]\n",
    "presencaNome = [(0, \"Faltou\"), (1, \"Presente\"), (2, \"Eliminado\")]\n",
    "presencaDataframe = spark.createDataFrame(presencaNome, presencaColumns)\n",
    "presencaDataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Qual o número total de Inscritos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalInscritos = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            NumTotal AS TotalInscritos\n",
    "        FROM\n",
    "            totalEnemView \n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|TotalInscritos|\n",
      "+--------------+\n",
      "|       5783109|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "totalInscritos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Qual a média por disciplina?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaDisciplinas = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            A.MediaCN,\n",
    "            B.MediaCH,\n",
    "            C.MediaLC,\n",
    "            D.MediaMT,\n",
    "            E.MediaRedacao\n",
    "        FROM\n",
    "            (SELECT\n",
    "                ROUND(AVG(NotaCN), 2) AS MediaCN\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                NotaCN IS NOT NULL\n",
    "            ) AS A,\n",
    "            (SELECT\n",
    "                ROUND(AVG(NotaCH), 2) AS MediaCH\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                NotaCH IS NOT NULL\n",
    "            ) AS B,\n",
    "            (SELECT\n",
    "                ROUND(AVG(NotaLC), 2) AS MediaLC\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                NotaLC IS NOT NULL\n",
    "            ) AS C,\n",
    "            (SELECT\n",
    "                ROUND(AVG(NotaMT), 2) AS MediaMT\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                NotaMT IS NOT NULL\n",
    "            ) AS D,\n",
    "            (SELECT\n",
    "                ROUND(AVG(NotaRedacao), 2) AS MediaRedacao\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE\n",
    "                NotaRedacao IS NOT NULL\n",
    "            ) AS E\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+------------+\n",
      "|MediaCN|MediaCH|MediaLC|MediaMT|MediaRedacao|\n",
      "+-------+-------+-------+-------+------------+\n",
      "| 490.41| 511.15|  523.8| 520.58|      573.41|\n",
      "+-------+-------+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mediaDisciplinas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Qual a média por Sexo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaSexo = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            Sexo,\n",
    "            ROUND(AVG(((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5)), 2) AS MediaNotaSexo\n",
    "        FROM\n",
    "            enemView\n",
    "        WHERE \n",
    "                NotaMT IS NOT NULL\n",
    "            AND\n",
    "                NotaCH IS NOT NULL\n",
    "            AND\n",
    "                NotaCN IS NOT NULL\n",
    "            AND\n",
    "                NotaLC IS NOT NULL\n",
    "            AND \n",
    "                NotaRedacao IS NOT NULL\n",
    "        GROUP BY Sexo\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|Sexo|MediaNotaSexo|\n",
      "+----+-------------+\n",
      "|   F|       521.24|\n",
      "|   M|       534.73|\n",
      "+----+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 185:====================>                                  (6 + 10) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mediaSexo.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Qual a média por Etnia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaEtnia = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            B.nomeEtnia AS Etnia,\n",
    "            A.MediaNotaEtnia\n",
    "        FROM\n",
    "            (SELECT\n",
    "                Etnia,\n",
    "                ROUND(AVG(((NotaCN+NotaCH+NotaLC+NotaMT+NotaRedacao)/5)), 2) AS MediaNotaEtnia\n",
    "            FROM\n",
    "                enemView\n",
    "            WHERE \n",
    "                    NotaMT IS NOT NULL\n",
    "                AND\n",
    "                    NotaCH IS NOT NULL\n",
    "                AND\n",
    "                    NotaCN IS NOT NULL\n",
    "                AND\n",
    "                    NotaLC IS NOT NULL\n",
    "                AND \n",
    "                    NotaRedacao IS NOT NULL\n",
    "            GROUP BY Etnia) A\n",
    "        INNER JOIN\n",
    "            etniaView B\n",
    "        ON codEtnia == Etnia\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:=====================================>                 (11 + 5) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|        Etnia|MediaNotaEtnia|\n",
      "+-------------+--------------+\n",
      "|Nao declarado|        534.05|\n",
      "|       Branca|        556.53|\n",
      "|        Preta|        500.87|\n",
      "|        Parda|        508.66|\n",
      "|      Amarela|        524.94|\n",
      "|     Indigena|        472.84|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mediaEtnia.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
